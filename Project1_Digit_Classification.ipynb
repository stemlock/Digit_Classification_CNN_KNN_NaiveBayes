{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6UHmLYVhWAN"
   },
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03M_JSg3hWAO"
   },
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "* Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "* Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Finally, if you'd like to get started with Tensorflow, you can read through this tutorial: https://www.tensorflow.org/tutorials/keras/basic_classification. It uses a dataset called \"fashion_mnist\", which is identical in structure to the original digit mnist, but uses images of clothing rather than images of digits. The number of training examples and number of labels is the same. In fact, you can simply replace the code that loads \"fashion_mnist\" with \"mnist\" and everything should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJ9ayCvyhWAP"
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO1t0ypThWAR"
   },
   "source": [
    "Load the data. Notice that the data gets partitioned into training, development, and test sets. Also, a small subset of the training data called mini_train_data and mini_train_labels gets defined, which you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yK9DacchWAS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (70000, 784)\n",
      "label shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the digit data from https://www.openml.org/d/554 or from default local location '~/scikit_learn_data/...'\n",
    "X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False)\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply \n",
    "# this permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atc2JpWKhWAV"
   },
   "source": [
    "### Part 1:\n",
    "\n",
    "Show a 10x10 grid that visualizes 10 examples of each digit.\n",
    "\n",
    "Notes:\n",
    "* You can use `plt.rc()` for setting the colormap, for example to black and white.\n",
    "* You can use `plt.subplot()` for creating subplots.\n",
    "* You can use `plt.imshow()` for rendering a matrix.\n",
    "* You can use `np.array.reshape()` for reshaping a 1D feature vector into a 2D matrix (for rendering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "436UeH7JhWAW"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def create_grid(data, labels, digits=range(0,10), num_examples=10, figsize=(20,20), axes='off'):\n",
    "    \n",
    "    '''\n",
    "    Creates a grid that visualizes a specified number of examples of\n",
    "    each digit specified in the digits array. Each row in the grid contains\n",
    "    the number of examples and each column is the range of digits in the\n",
    "    digits array in descending order. By default, the digits are 0-9 and\n",
    "    the number of examples is set to 10.\n",
    "    '''\n",
    "    \n",
    "    # Create the grid of subplots\n",
    "    fig, ax = plt.subplots(len(digits), num_examples, figsize=figsize)\n",
    "    \n",
    "    # Create a counter of examples for each digit and a set that breaks the loop \n",
    "    # when all digits have been added to it\n",
    "    counter_list = [0] * len(digits)\n",
    "    break_set = set()\n",
    "    \n",
    "    # Loop through the data and labels and plot the appropriate digits until the \n",
    "    # number of examples has been reached for each digit\n",
    "    for digit, label in zip(data, labels):\n",
    "        \n",
    "        label = int(label)\n",
    "        \n",
    "        # Skip the label if it is not one of the specified digits\n",
    "        if label not in digits:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            if counter_list[digits.index(label)] < num_examples:\n",
    "                grid = digit.reshape((28,28))\n",
    "                \n",
    "                # If there is only one digit specified, the subplots are in a 1-dimensional array\n",
    "                if len(digits) == 1:\n",
    "                    plot_digit(grid, ax[counter_list[digits.index(label)]], axes=axes)\n",
    "                \n",
    "                # Else, the subplots are in a 2-dimensional array\n",
    "                else:\n",
    "                    plot_digit(grid, ax[digits.index(label)][counter_list[digits.index(label)]], axes=axes)\n",
    "                    \n",
    "                counter_list[digits.index(label)] += 1\n",
    "\n",
    "            elif counter_list[digits.index(label)] == num_examples:\n",
    "                break_set.add(label)\n",
    "\n",
    "            if len(break_set) == len(digits):\n",
    "                break\n",
    "    \n",
    "    # Show the final grid\n",
    "    fig.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "def plot_digit(digit, ax, axes):\n",
    "    \n",
    "    '''\n",
    "    Renders/plots the digit matrix on top of a specified ax.\n",
    "    '''\n",
    "    \n",
    "    # Plot the digit matrix and turn off the axis labels\n",
    "    ax.imshow(digit, cmap ='Greys', vmin = 0, vmax = 1) \n",
    "    ax.axis(axes)\n",
    "\n",
    "create_grid(dev_data, dev_labels)\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMQAHr7QhWAX"
   },
   "source": [
    "### Part 2:\n",
    "\n",
    "Produce k-Nearest Neighbors models with k $\\in$ [1,3,5,7,9].  Evaluate and show the accuracy of each model. For the 1-Nearest Neighbor model, additionally show the precision, recall, and F1 for each label. Which digit is the most difficult for the 1-Nearest Neighbor model to recognize?\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
    "* You can use `classification_report` to get precision, recall, and F1 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-it5pn8-hWAY"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def KNN_model_predict(k, train_data, train_labels, eval_data):\n",
    "    \n",
    "    '''\n",
    "    Creates a k-Nearest-Neighbors model based on some input k, which is then\n",
    "    fit to some training data set and used to predict some evaluation set, \n",
    "    the results of which are then returned as output.\n",
    "    '''\n",
    "    \n",
    "    model_KNN = KNeighborsClassifier(k)\n",
    "    model_KNN.fit(train_data, train_labels)\n",
    "    return model_KNN.predict(eval_data)\n",
    "\n",
    "def KNN_prediction_scores(k_values, train_data, train_labels, eval_data, eval_labels):\n",
    "    \n",
    "    '''\n",
    "    Calculates and displays the prediction accuracy scores for a range of k-Nearest-Neighbors \n",
    "    models with varying k values that are all trained and evaluated based on an input training\n",
    "    data set and evaluation data set respectively.\n",
    "    '''\n",
    "    \n",
    "    # For every value of k, calculate and print the prediction accuracy results\n",
    "    for k in k_values:\n",
    "        \n",
    "        print(f\"K = {k}:\")\n",
    "        predicts = KNN_model_predict(k, train_data, train_labels, eval_data)\n",
    "        \n",
    "        # If model is 1NN, print the whole classification report\n",
    "        if k == 1:\n",
    "            print(classification_report(eval_labels, predicts))\n",
    "\n",
    "        # Else for k > 1, only print the overall accuracy score\n",
    "        else:\n",
    "            \n",
    "            print(\"Accuracy score -\", classification_report(eval_labels, predicts, output_dict=True)['accuracy'])\n",
    "            print()\n",
    "\n",
    "            \n",
    "# List of k values to be used in the models            \n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Return the different metrics\n",
    "KNN_prediction_scores(k_values, mini_train_data, mini_train_labels, dev_data, dev_labels) \n",
    "\n",
    "### STUDENT END ###\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZc9gzn5hWAZ"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "In terms of precision, the 1-Nearest Neighbor model has the most difficult time recognizing the digit 9, where precision is the accuracy of positive predictions. However, there are two other metrics to determine accuracy of predictions, which are recall and f1-score. For recall, the most diffcult digit to recognize was 8, which means that the model had the most difficult time correctly identified the positives for it. Finally, for the f1-score, the model again had the most difficult time predicted the digit 8, where the f1-score is the harmonious mean (a mean measure used for rates) of precision and recall. \n",
    "\n",
    "Thus, overall it would be fair to say that the model had the most difficult time recognizing the digit 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the np.linalg.norm function to calculate the Ln Norm (default parameter of 2 = Euclidean distance)\n",
    "def EuclideanDistance(v1, v2):\n",
    "    return np.linalg.norm(v1 - v2)\n",
    "\n",
    "# Compute all pairwise distances in the training data and store it in the list to plot on a histogram\n",
    "dists = []\n",
    "for i in range(len(mini_train_data) - 1):\n",
    "    for j in range(i + 1, len(mini_train_data)):\n",
    "        dist = EuclideanDistance(mini_train_data[i], mini_train_data[j])\n",
    "        dists.append(dist)\n",
    "\n",
    "# Plot the histogram distribution of the euclidean distances\n",
    "plt.hist(dists,100)\n",
    "plt.title(\"Pairwise Euclidean Distances between digits\")\n",
    "plt.ylabel(\"Number of pairs\")\n",
    "plt.xlabel(\"Euclidean distance\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 1-NN class \n",
    "\n",
    "class NearestNeighbors:\n",
    "    # Initialize an instance of the class.\n",
    "    def __init__(self, metric=EuclideanDistance):\n",
    "        self.metric = metric\n",
    "    \n",
    "    # No training for Nearest Neighbors. Just store the data.\n",
    "    def fit(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    # Make predictions for each test example and return results.\n",
    "    def predict(self, test_data):\n",
    "        results = []\n",
    "        for item in test_data:\n",
    "            results.append(self._predict_item(item))\n",
    "        return results\n",
    "    \n",
    "    # Private function for making a single prediction.\n",
    "    def _predict_item(self, item):\n",
    "        best_dist, best_label = 1.0e10, None\n",
    "        for i in range(len(self.train_data)):\n",
    "            dist = self.metric(self.train_data[i], item)\n",
    "            if dist < best_dist:\n",
    "                best_label = self.train_labels[i]\n",
    "                best_dist = dist\n",
    "        return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the NearestNeighbors object\n",
    "clf = NearestNeighbors()\n",
    "\n",
    "# Store the train data in the NearestNeighbors object\n",
    "clf.fit(mini_train_data, mini_train_labels)\n",
    "\n",
    "#  Predict the label for each data point in the test data based on the nearest neighbor from the train data\n",
    "dev_preds = clf.predict(dev_data)\n",
    "print(classification_report(dev_labels, dev_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b6YEAzzhWAa"
   },
   "source": [
    "### Part 3:\n",
    "\n",
    "Produce 1-Nearest Neighbor models using training data of various sizes.  Evaluate and show the performance of each model.  Additionally, show the time needed to measure the performance of each model.\n",
    "\n",
    "Notes:\n",
    "* Train on subsets of the train set.  For each subset, take just the first part of the train set without re-ordering.\n",
    "* Evaluate on the dev set.\n",
    "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
    "* You can use `time.time()` to measure elapsed time of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEpNzDEjhWAa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def KNN_by_size(train_sizes, k, train_data, train_labels, eval_data, eval_labels):\n",
    "    \n",
    "    '''\n",
    "    Uses a K-Nearest-Neighbor model to make predictions based on a range of training\n",
    "    data set sizes. Displays the size of the training data set used, the prediction\n",
    "    accuracy score of the model on the evaluation data set, and the time needed for the \n",
    "    model to make the predictions. Returns the list of times and accuracies for each \n",
    "    training set size.\n",
    "    '''\n",
    "    \n",
    "    # Initialize empty lists to store the accuracy and elapsed time for each training set size\n",
    "    accuracies = []\n",
    "    times = []\n",
    "\n",
    "    # For each size in the range of training data set sizes, train a KNN model and calculate\n",
    "    # the prediction accuracy on the evaluation data set\n",
    "    for size in train_sizes:\n",
    "\n",
    "        # Capture the start time\n",
    "        start_secs = time.time()\n",
    "\n",
    "        predicts = KNN_model_predict(k, train_data[:size], train_labels[:size], eval_data)\n",
    "        print(f\"Size = {size}:\")\n",
    "\n",
    "        acc = classification_report(eval_labels, predicts, output_dict=True)['accuracy']\n",
    "        accuracies.append(acc)\n",
    "        print(\"Accuracy score -\", acc)\n",
    "\n",
    "        # Capture the end time\n",
    "        finish_secs = time.time()\n",
    "\n",
    "        # Calculate the elapsed time\n",
    "        elapsed = finish_secs - start_secs\n",
    "        times.append(elapsed)\n",
    "        print(f\"Time elapsed (seconds): {elapsed:.2f}\\n\")\n",
    "        \n",
    "    return times, accuracies\n",
    "\n",
    "# Create a range of train data set sizes to train the model on\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600]\n",
    "\n",
    "# Set the number of nearest neighnors\n",
    "k = 1\n",
    "\n",
    "# Show the performance and time elapsed for each training set size\n",
    "times, accuracies = KNN_by_size(train_sizes, k, train_data, train_labels, dev_data, dev_labels)\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_1NN_by_size(train_sizes, train_data, train_labels, eval_data, eval_labels):\n",
    "    \n",
    "    '''\n",
    "    Uses a custom 1-Nearest-Neighbor implementation to make predictions based on a range of \n",
    "    training data set sizes. Displays the size of the training data set used, the prediction\n",
    "    accuracy score of the model on the evaluation data set, and the time needed for the model \n",
    "    to make the predictions. Returns the list of times and accuracies for each training set size.\n",
    "    '''\n",
    "    \n",
    "    # Initialize empty lists to store the accuracy and elapsed time for each training set size\n",
    "    accuracies = []\n",
    "    times = []\n",
    "\n",
    "    # For each size in the range of training data set sizes, train a KNN model and calculate\n",
    "    # the prediction accuracy on the evaluation data set\n",
    "    for size in train_sizes:\n",
    "\n",
    "        # Capture the start time\n",
    "        start_secs = time.time()\n",
    "        \n",
    "        # Create the NearestNeighbors object\n",
    "        clf = NearestNeighbors()\n",
    "\n",
    "        # Store the train data in the NearestNeighbors object\n",
    "        clf.fit(train_data[:size], train_labels[:size])\n",
    "\n",
    "        #  Predict the label for each test data point based on the nearest neighbor from the train data\n",
    "        predicts = clf.predict(eval_data)\n",
    "        print(f\"Size = {size}:\")\n",
    "\n",
    "        acc = classification_report(eval_labels, predicts, output_dict=True)['accuracy']\n",
    "        accuracies.append(acc)\n",
    "        print(\"Accuracy score -\", acc)\n",
    "\n",
    "        # Capture the end time\n",
    "        finish_secs = time.time()\n",
    "\n",
    "        # Calculate the elapsed time\n",
    "        elapsed = finish_secs - start_secs\n",
    "        times.append(elapsed)\n",
    "        print(f\"Time elapsed (seconds): {elapsed:.2f}\\n\")\n",
    "        \n",
    "    return times, accuracies\n",
    "\n",
    "custom_1NN_by_size(train_sizes, train_data, train_labels, dev_data, dev_labels)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train data set size vs the prediction accuracy, with the points color labelled with the time elapsed\n",
    "\n",
    "# Change the accuracies to 0-100%\n",
    "accuracies_pct = np.multiply(accuracies, 100)\n",
    "\n",
    "# Create the figure and the scatter plot with color scheme set to the times\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(train_sizes, accuracies_pct, c=times)\n",
    "plt.colorbar(pad=0.1).set_label(\"Time elpased (seconds)\")\n",
    "\n",
    "# For each point on the scatter plot, add a text annotation with the time\n",
    "for t,a,size in zip(times, accuracies_pct, train_sizes):\n",
    "    plt.annotate(f\"{t:.2f}s\", (size, a), xytext=(size+400, a-0.75))\n",
    "    \n",
    "# Plot the line plot of the train size vs accuracy\n",
    "plt.plot(train_sizes, accuracies_pct, '-r')\n",
    "plt.title(\"1NN Model Accuracy vs Train Data Size\")\n",
    "plt.xlabel(\"Train dataset size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B56lVsKNhWAc"
   },
   "source": [
    "### Part 4:\n",
    "\n",
    "Produce a linear regression model that predicts accuracy of a 1-Nearest Neighbor model given training set size. Show $R^2$ of the linear regression model.  Show the accuracies predicted for training set sizes 60000, 120000, and 1000000.  Show a lineplot of actual accuracies and predicted accuracies vs. training set size over the range of training set sizes in the training data.  What's wrong with using linear regression here?\n",
    "\n",
    "Apply a transformation to the predictor features and a transformation to the outcome that make the predictions more reasonable.  Show $R^2$ of the improved linear regression model.  Show the accuracies predicted for training set sizes 60000, 120000, and 1000000.  Show a lineplot of actual accuracies and predicted accuracies vs. training set size over the range of training set sizes in the training data - be sure to display accuracies and training set sizes in appropriate units.\n",
    "\n",
    "Notes:\n",
    "* Train the linear regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
    "* Evaluate the linear regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
    "* You can use `LinearRegression` to produce a linear regression model.\n",
    "* Remember that the sklearn `fit()` functions take an input matrix X and output vector Y. So, each input example in X is a vector, even if it contains only a single value.\n",
    "* Hint re: predictor feature transform: Accuracy increases with training set size logarithmically.\n",
    "* Hint re: outcome transform: When y is a number in range 0 to 1, then odds(y)=y/(1-y) is a number in range 0 to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xE_qIJghWAc"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def LR_predict(train_x, train_y, to_predict):\n",
    "    \n",
    "    '''\n",
    "    Uses a linear regression model to predict the accuracy of a 1NN model\n",
    "    given an input training set size by training the regression model on a set \n",
    "    of train sizes and accuracies outputted from the 1NN model. Calculates and \n",
    "    displays the R^2 value of the model as well as the predicted accuracies for\n",
    "    a some training set sizes. Returns the training sizes and the predicted accuracies \n",
    "    '''\n",
    "\n",
    "    # If either of the train_x or train_x sets are not np.arrays, convert and reshape them\n",
    "    if type(train_x) != np.array:\n",
    "        train_x = np.array(train_x).reshape(-1,1)\n",
    "\n",
    "    if type(train_y) != np.array:\n",
    "        train_y = np.array(train_y).reshape(-1,1) \n",
    "    \n",
    "    # Fit the linear regression model and print the R^2 value\n",
    "    reg = LinearRegression().fit(train_x, train_y)\n",
    "    print(f\"Linear Regression Model, R\\u00b2: {reg.score(train_x, train_y):.4f}\")\n",
    "    \n",
    "    # Stack the training set sizes and predict the respective accuracies \n",
    "    predict_x = np.vstack((train_x, to_predict))\n",
    "    predictions = reg.predict(predict_x)\n",
    "\n",
    "    # Print the linear regression model accuracy for the to_predict training set sizes\n",
    "    for x, y in zip(to_predict, predictions[len(predictions)-3:]):\n",
    "        if x < 100:\n",
    "            x = np.exp(x)\n",
    "        print(f\"Model accuracy prediction given training set size {x[0]:.0f} -> {y[0]*100:.2f}% accuracy\")\n",
    "        \n",
    "    return predict_x, predictions\n",
    "\n",
    "# Store the training set sizes to be predicted in a np.array\n",
    "predicts = np.array([[60000], [120000], [1000000]])\n",
    "\n",
    "# Make the predictions\n",
    "LR_train_sizes, LR_accuracies = LR_predict(train_sizes, accuracies, predicts)\n",
    "\n",
    "# Change the actual accuracies to 0-100%\n",
    "accuracies_pct = np.multiply(accuracies, 100)\n",
    "\n",
    "# Plot the regression line and the actual 1NN accuracies scatter plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train_sizes, accuracies_pct)\n",
    "plt.plot(train_sizes, accuracies_pct, label=\"Actual accuracies\")\n",
    "plt.plot(LR_train_sizes, np.multiply(LR_accuracies, 100), '-r', label = \"Linear regression model accuracies\")\n",
    "plt.title(\"Figure 1. Actual Prediction Accuracies vs Linear Regression Model Predicted Accuracies\")\n",
    "plt.xlabel(\"Training set size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.xlim(0, 27000)\n",
    "plt.ylim(70,100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a natural log transform on both the train_sizes and the sizes to predicted\n",
    "log_train_sizes = np.log(train_sizes)\n",
    "log_predicts = np.log(predicts)\n",
    "\n",
    "# Make the predictions\n",
    "LR_log_train_sizes, LR_accuracies = LR_predict(log_train_sizes, accuracies, log_predicts)\n",
    "\n",
    "# Plot the regression line of the log relationship and the log of the actual 1NN accuracies scatter plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train_sizes, accuracies_pct)\n",
    "plt.plot(train_sizes, accuracies_pct, label=\"Actual accuracies\")\n",
    "plt.plot(LR_train_sizes, np.multiply(LR_accuracies, 100), '-r', label = \"Log transformed linear regression model accuracies\")\n",
    "\n",
    "plt.title(\"Figure 2. Actual Prediction Accuracies vs Log Transformed Linear Regression Model Predicted Accuracies\")\n",
    "plt.xlabel(\"Training set size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.ylim(70,100)\n",
    "plt.xlim(-100,30000)\n",
    "plt.show()\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYYYL9cGhWAe"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "The problem with using linear regression to predict the accuracy of a certain training set size in classifying the images in the MNIST dataset into the correct digits is due to the fact that the relationship between training set size and accuracy is not linear (as can be seen in Figure 1). In actuality, the relationship is better described as a logarithmic relationship, as can be seen in Figure 2 above. As the training set size increases, the  prediction accuracy does improve, but the rate of improvement decreases as the training set size continues to grow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geAQJjGRhWAe"
   },
   "source": [
    "### Part 5:\n",
    "\n",
    "Produce a 1-Nearest Neighbor model and show the confusion matrix. Which pair of digits does the model confuse most often? Show the images of these most often confused digits.\n",
    "\n",
    "Notes:\n",
    "- Train on the mini train set.\n",
    "- Evaluate performance on the dev set.\n",
    "- You can use `confusion_matrix()` to produce a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bq36xaQohWAf"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "            \n",
    "def plot_confusion_matrix(actual, predicted):\n",
    "    \n",
    "    '''\n",
    "    Plots the confusion matrix of the actual labels vs the predicted labels \n",
    "    and marks the most confused pairing of actual vs predicted labels in red text.\n",
    "    Returns the coordinates of the most confused pair.\n",
    "    '''\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    \n",
    "    # Plot the confusion matrix \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm)\n",
    "    \n",
    "    plt.title(\"Confusion Matrix (red text is the most confused pair)\")\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.xticks(np.arange(10))\n",
    "    plt.yticks(np.arange(10))\n",
    "    \n",
    "    most = 0\n",
    "    coord = (0,0)\n",
    "    \n",
    "    # Loop through the confusion matrix and annotate each confusion pair\n",
    "    # while finding the value and the coordinates of the highest confusion pair\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            \n",
    "            if i != j:\n",
    "                if cm[i,j] > most:\n",
    "                    most = cm[i,j]\n",
    "                    coord = i,j    \n",
    "                    \n",
    "            plt.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"w\")\n",
    "    \n",
    "    # Annotate the highest confusion pair in red text\n",
    "    plt.text(coord[1], coord[0], most, ha=\"center\", va=\"center\", color=\"r\", fontweight=\"extra bold\")\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def find_confused(actual, predicted, most_confused):\n",
    "    \n",
    "    '''\n",
    "    Finds and returns the indices in the data set that holds the most confused digits.\n",
    "    '''\n",
    "    \n",
    "    # Create a truth matrix where the actual labels do not equal the predicted labels\n",
    "    compare = (actual != predicted)\n",
    "    \n",
    "    confused_indices = []\n",
    "    \n",
    "    # Loop through the values where actual != predicted and append the indices of\n",
    "    # the most confused digits\n",
    "    for i in range(0, len(compare)):\n",
    "        if compare[i]:\n",
    "            if  int(actual[i]) == most_confused[0] and int(predicted[i]) == most_confused[1]:\n",
    "                confused_indices.append(i)\n",
    "                \n",
    "    return confused_indices \n",
    "\n",
    "# Predict the dev labels with a 1NN model\n",
    "predicted = KNN_model_predict(1, mini_train_data, mini_train_labels, dev_data)\n",
    "\n",
    "# Plot the confusion matrix and find the most confused pair\n",
    "most_confused_pair = plot_confusion_matrix(dev_labels, predicted)\n",
    "\n",
    "# Find the indices of actual digit of the most confused pair\n",
    "confused = find_confused(dev_labels, predicted, most_confused_pair)\n",
    "    \n",
    "# Plot the most confused digits\n",
    "create_grid(dev_data[np.array(confused)], dev_labels[np.array(confused)], digits=[most_confused_pair[0]], \n",
    "               num_examples = len(confused), figsize=(10,10))\n",
    "\n",
    "### STUDENT END ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "1-Nearest Neighbor model confuses the digit 4 as a 9 most often out of all digit pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgqMKb-hhWAh"
   },
   "source": [
    "### Part 6:\n",
    "\n",
    "A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian, i.e., the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur filter by just using the 8 neighboring pixels like this: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values.\n",
    "\n",
    "Pick a weight, then produce and evaluate four 1-Nearest Neighbor models by applying your blur filter in these ways:\n",
    "- Do not use the filter\n",
    "- Filter the training data but not the dev data\n",
    "- Filter the dev data but not the training data\n",
    "- Filter both training data and dev data\n",
    "\n",
    "Show the accuracies of the four models evaluated as described.  Try to pick a weight that makes one model's accuracy at least 0.9.\n",
    "\n",
    "Notes:\n",
    "* Train on the (filtered) mini train set.\n",
    "* Evaluate performance on the (filtered) dev set.\n",
    "* There are other Guassian blur filters available, for example in `scipy.ndimage.filters`. You are welcome to experiment with those, but you are likely to get the best results with the simplified version described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSKHmHGshWAi"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def guassian_function(x, y, sigma):\n",
    "    \n",
    "    '''\n",
    "    Computes the weight of a coordinate using the two dimensional\n",
    "    Gaussian distribution function.\n",
    "    '''\n",
    "    \n",
    "    sigma_sq = sigma**2\n",
    "    x_sq = x**2\n",
    "    y_sq = y**2\n",
    "    \n",
    "    ans = 1/(2 * np.pi * sigma_sq)\n",
    "    ans *= np.exp(-(x_sq+y_sq)/(2*sigma_sq))\n",
    "    \n",
    "    return ans\n",
    "\n",
    "def weighted_matrix(sigma, blur_radius=1):\n",
    "\n",
    "    '''\n",
    "    Creates a weighted matrix to use for blurring based on a weight value (sigma) \n",
    "    and blur radius, which is the number of adjacent coordinates to be used in the \n",
    "    weighted matrix. For example, a blur radius of 1 will result in 8 neighboring \n",
    "    coordinates, while a radius of 2 will result in 24 neighbors.\n",
    "    '''\n",
    "    \n",
    "    # Find the edges and the dimensions of the matrix\n",
    "    neg_edge = -1*blur_radius\n",
    "    pos_edge = blur_radius+1\n",
    "    dim = pos_edge - neg_edge\n",
    "    \n",
    "    # Initialize an empty matrix with appropriate size\n",
    "    w_matrix = np.empty(shape=(dim,dim))\n",
    "    w_sum = 0\n",
    "    \n",
    "    # Calculate the weight for each coordinate in the matrix based off it's distance \n",
    "    # from the central coordinate and the sigma value\n",
    "    for i in range(neg_edge, pos_edge):\n",
    "        for j in range(neg_edge, pos_edge):\n",
    "            w_matrix[i+blur_radius][j+blur_radius] = guassian_function(i, j, sigma)\n",
    "            w_sum += w_matrix[i+blur_radius][j+blur_radius]\n",
    "    \n",
    "    # Normalize the matrix by dividing by the weighted sum\n",
    "    w_matrix = np.divide(w_matrix, w_sum)\n",
    "            \n",
    "    return w_matrix\n",
    "\n",
    "\n",
    "def blur_data(data, w_matrix, blur_radius=1):\n",
    "    \n",
    "    '''\n",
    "    Applies a blur filter to the input data using the weighted matrix. \n",
    "    The blur radius used should be equal to the radius applied when \n",
    "    creating the weighted matrix.\n",
    "    '''\n",
    "    \n",
    "    # Initialize blurred_data to be hold all the blurred samples\n",
    "    blurred_data = np.empty_like(data)\n",
    "        \n",
    "    # Loop through each sample in the data and apply the blurring filter \n",
    "    for s,sample in enumerate(data):\n",
    "\n",
    "        # Reshape the sample in pixel form and initiliaze a temporary data point\n",
    "        sample = sample.reshape(28,28)\n",
    "        blurred_sample = np.empty_like(sample, dtype=float)\n",
    "\n",
    "        # Apply a padding of 0's to the edges of the sample to allow for blurring\n",
    "        for i in range(0, blur_radius):\n",
    "\n",
    "            zero_col = np.zeros((len(sample),1))\n",
    "            sample = np.hstack((zero_col, sample, zero_col))\n",
    "\n",
    "            zero_row = np.zeros(len(sample[0]))\n",
    "            sample = np.vstack((zero_row, sample, zero_row))\n",
    "            \n",
    "        # For each coordinate in the sample, multiply itself and it's neighboring coordinates \n",
    "        # by the weighted matrix\n",
    "        for y in range(blur_radius, len(sample) - blur_radius):\n",
    "            for x in range(blur_radius, len(sample) - blur_radius):\n",
    "                mini_array = sample[y-blur_radius:y+blur_radius+1,x-blur_radius:x+blur_radius+1]\n",
    "                blurred_sample[y-blur_radius,x-blur_radius] = np.sum(mini_array*w_matrix)\n",
    "         \n",
    "        # Add the blurred sample to the blurred_data data set\n",
    "        blurred_data[s] = blurred_sample.reshape((1,784))\n",
    "        \n",
    "    return blurred_data\n",
    "\n",
    "# Set the hyperparameters (blur radius, sigma weight, and k values for nearest neighbors)\n",
    "radius = 1\n",
    "sigma = 1.2\n",
    "k_values = [1]\n",
    "\n",
    "# Create the weighted matrix\n",
    "w_matrix = weighted_matrix(sigma, blur_radius=radius)\n",
    "\n",
    "# Blur the train and dev datasets\n",
    "mini_train_blur = blur_data(mini_train_data, w_matrix, blur_radius=radius)\n",
    "dev_blur = blur_data(dev_data, w_matrix, blur_radius=radius)\n",
    "\n",
    "# 1NN prediction with no filter\n",
    "print(\"1-Nearest Neighbor model without a blur filter\\n\")\n",
    "KNN_prediction_scores(k_values, mini_train_data, mini_train_labels, dev_data, dev_labels)\n",
    "\n",
    "# 1NN prediction with blur filter on training data\n",
    "print(\"1-Nearest Neighbor model with a blur filter on training data\\n\")\n",
    "KNN_prediction_scores(k_values, mini_train_blur, mini_train_labels, dev_data, dev_labels)\n",
    "\n",
    "# 1NN prediction with blur filter on the dev data\n",
    "print(\"1-Nearest Neighbor model with a blur filter on evaluation data\\n\")\n",
    "KNN_prediction_scores(k_values, mini_train_data, mini_train_labels, dev_blur, dev_labels)\n",
    "\n",
    "# 1NN prediction with blur filter on both training and dev data\n",
    "print(\"1-Nearest Neighbor model with a blur filter on both the training and evaluation data\\n\")\n",
    "KNN_prediction_scores(k_values, mini_train_blur, mini_train_labels, dev_blur, dev_labels)\n",
    "\n",
    "### STUDENT END ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the blur effect on the data\n",
    "create_grid(mini_train_blur, mini_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtgepWfAhWAk"
   },
   "source": [
    "### Part 7:\n",
    "\n",
    "Produce two Naive Bayes models and evaluate their performances.  Recall that Naive Bayes estimates P(feature|label), where each label is a categorical, not a real number.\n",
    "\n",
    "For the first model, map pixel values to either 0 or 1, representing white or black - you should pre-process the data or use `BernoulliNB`'s `binarize` parameter to set the white/black separation threshold to 0.1.  Use `BernoulliNB` to produce the model.\n",
    "\n",
    "For the second model, map pixel values to either 0, 1, or 2, representing white, gray, or black - you should pre-process the data, seting the white/gray/black separation thresholds to 0.1 and 0.9.  Use `MultinomialNB` to produce the model. \n",
    "\n",
    "Show the Bernoulli model accuracy and the Multinomial model accuracy.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* `sklearn`'s Naive Bayes methods can handle real numbers, but for this exercise explicitly do the mapping to categoricals. \n",
    "\n",
    "Does the multinomial version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGpH-4IQhWAk"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def map_continuous(data, thresholds=[], right=False):\n",
    "    \n",
    "    '''\n",
    "    A function that takes as input a set of continuous data and maps the features \n",
    "    into n discrete bins from 0 to n-1 based on the thresholds provided for each feature, \n",
    "    where n-1 is the number thresholds specified per feature. If the thresholds are \n",
    "    not provided, the function will binarize (0,1) the values by using the mean \n",
    "    of each feature as the threshold.\n",
    "    '''\n",
    "    \n",
    "    # Calculate the threshold for each feature if it was not passed in as an argument\n",
    "    if not thresholds:\n",
    "        for i in range(data.shape[1]):\n",
    "            thresholds.append([data[:,i].mean()])\n",
    "    \n",
    "    # Initialize a new feature array with the same shape as the original data.\n",
    "    mapped_data = np.empty(data.shape)\n",
    "\n",
    "    # Digitize each feature and map them to bins between 0 to number of thresholds\n",
    "    for feature in range(data.shape[1]):\n",
    "        mapped_data[:,feature] = np.digitize(data[:,feature], thresholds[feature], right=right)\n",
    "\n",
    "    return mapped_data, thresholds\n",
    "\n",
    "# Binarize the mini_train and dev datasets\n",
    "bin_mini_train_data, bin_thresholds = map_continuous(mini_train_data, thresholds=[[0.1]]*784)\n",
    "bin_dev_data, bin_thresholds = map_continuous(dev_data, thresholds=[[0.1]]*784)\n",
    "\n",
    "# Ternarize the mini_train and dev datasets\n",
    "tern_mini_train_data, thresholds = map_continuous(mini_train_data, thresholds=[[0.1,0.9]]*784)\n",
    "tern_dev_data, thresholds = map_continuous(dev_data, thresholds=[[0.1,0.9]]*784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict the Bernoulli model\n",
    "bernoulli = BernoulliNB(binarize=None)\n",
    "bernoulli.fit(bin_mini_train_data, mini_train_labels)\n",
    "bin_predicts = bernoulli.predict(bin_dev_data)\n",
    "\n",
    "# Fit and predict the Multinomial model\n",
    "multi = MultinomialNB()\n",
    "multi.fit(tern_mini_train_data, mini_train_labels)\n",
    "multi_predicts = multi.predict(tern_dev_data)\n",
    "\n",
    "# Print the accuracy scores for each model\n",
    "print(\"Bernoulli NB accuracy score -\", classification_report(dev_labels, bin_predicts, output_dict=True)['accuracy'])\n",
    "print(\"Multinomial NB accuracy score -\", classification_report(dev_labels, multi_predicts, output_dict=True)['accuracy'])\n",
    "\n",
    "# Plot the histogram of the normalized greyscale values of the mini_train_data\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(mini_train_data.ravel(), bins=50)\n",
    "plt.title(\"Distribution of Pixels in Mini Train Data\")\n",
    "plt.xlabel(\"Normalized pixel greyscale value\")\n",
    "plt.xticks(np.arange(0,1.1,0.1))\n",
    "plt.show()\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNLrgggohWAm"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "The Multinomial Naive Bayes model does not improve the results of the accuracy score, and in fact reduces the accuracy score. \n",
    "\n",
    "Firstly, the Multinomial score is very similar to the Bernoulli score given that the majority of pixels have values at the extreme ends of the normalized scores (close to 0 or 1). This can be seen from the histogram above. As a result, creating a third class for grey between 0.1 and 0.9 does not account for very many of the pixels, and therefore should not affect the overall accuracy score very much.\n",
    "\n",
    "The observed slight decrease in score is likely due to the fact that the Naive Bayes algorithm assumes that the features (in this case each pixel) are indepedent. Given this independence assumption, we assume that the probability of seeing a white pixel vs a grey pixel vs a black pixel is independent, even though these values will be dependent on the other pixels around them. Therefore, separating out a black pixel (0.1-1) in the binomial case into either a grey pixel (0.1-0.9) or black pixel (0.9-1) will lower the frequencies of each of these pixels occuringã€€(although very slightly). Thus, the multinomial model will have a more difficult time predicting the labels (or digits) for black given that it has less confidence to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 100 evenly spaced thresholds on the mini_train and dev datasets\n",
    "hun_mini_train_data, hun_thresholds = map_continuous(mini_train_data, thresholds=[[0.01*i for i in range(1,100)]]*784)\n",
    "hun_dev_data, hun_thresholds = map_continuous(dev_data, thresholds=[[0.01*i for i in range(1,100)]]*784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multinomial using 100 discrete values for each feature\n",
    "hun = MultinomialNB()\n",
    "hun.fit(hun_mini_train_data, mini_train_labels)\n",
    "hun_predicts = hun.predict(dev_data)\n",
    "print(\"100 NB Accuracy score -\", classification_report(dev_labels, hun_predicts, output_dict=True)['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the reports for bernoulli, multinomial 3, and multinomial 100\n",
    "print(classification_report(dev_labels, bin_predicts))\n",
    "print(classification_report(dev_labels, multi_predicts))\n",
    "print(classification_report(dev_labels, hun_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PqjbRLg7hWAm"
   },
   "source": [
    "### Part 8:\n",
    "\n",
    "Search across several values of the LaPlace smoothing parameter (alpha) to find its effect on a Bernoulli Naive Bayes model's performance.  Show the accuracy at each alpha value.\n",
    "\n",
    "Notes:\n",
    "* Set binarization threshold to 0.\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance by 5-fold cross-validation. \n",
    "* Use `GridSearchCV(..., ..., cv=..., scoring='accuracy', iid=False)` to vary alpha and evaluate performance by cross-validation.\n",
    "* Cross-validation is based on partitions of the training data, so results will be a bit different than if you had used the dev set to evaluate performance.\n",
    "\n",
    "What is the best value for alpha? What is the accuracy when alpha is near 0? Is this what you'd expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AvZ-Wp3hWAn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "# Binarize the mini_train and dev datasets with a thresold of 0\n",
    "zero_mini_train_data, zero_thresholds = map_continuous(mini_train_data, thresholds=[[0]]*784, right=True)\n",
    "\n",
    "# Set the alphas to be tested\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "# Initialize the GridSearchCV function with a Bernoulli NB classifier and the alpha\n",
    "gridsearch = GridSearchCV(BernoulliNB(binarize=None), param_grid=alphas)\n",
    "gridsearch.fit(zero_mini_train_data, mini_train_labels)\n",
    "\n",
    "# Print the mean test score for each alpha value\n",
    "scores = iter(gridsearch.cv_results_['mean_test_score'])\n",
    "for alpha in gridsearch.cv_results_['param_alpha']: \n",
    "    print(f\"Alpha value - {alpha}:\".ljust(21), f\"{next(scores):.3f}\")\n",
    "\n",
    "\n",
    "# Find the best alpha and score\n",
    "alpha = gridsearch.best_params_['alpha']\n",
    "print()\n",
    "print(\"Best alpha:\", alpha)\n",
    "print(\"Score for best alpha:\", gridsearch.best_score_)\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yEg9keThWAp"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "The best value of alpha according to the GridSearch was the alpha value of 0.001, which return an accuracy score of 0.825. However, the range of prediction scores across the different values of alpha was relatively small, with only a 4% difference between the worst and best cases. When the alpha value was near 0, the prediction accuracy was 0.814, which is only slightly less than the best accuracy score. This small difference between the alpha values besides the huge variation in the value itself is expected given the fact that we have dense data given the MNIST data set. Specifically, each pixel takes on a value of 0 or 1, meaning we do not have any missing data. Therefore, the alpha smoothing that is added to the frequencies will have minimal effect as the counts will take into account every example within the training data set. Most likely, for much larger values of alpha we will likely see the test scores decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the alphas to be tested\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 100.0]}\n",
    "\n",
    "# Initialize the GridSearchCV function with a Bernoulli NB classifier and the alpha\n",
    "gridsearch = GridSearchCV(BernoulliNB(binarize=None), param_grid=alphas)\n",
    "gridsearch.fit(zero_mini_train_data, mini_train_labels)\n",
    "\n",
    "# Print the mean test score for each alpha value\n",
    "scores = iter(gridsearch.cv_results_['mean_test_score'])\n",
    "for alpha in gridsearch.cv_results_['param_alpha']: \n",
    "    print(f\"Alpha value - {alpha}:\".ljust(21), f\"{next(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.log10(alphas['alpha']), gridsearch.cv_results_['mean_test_score']*100, marker='*')\n",
    "plt.title(\"Laplace Smoothing vs Test Score\")\n",
    "plt.ylabel(\"Test Score %\")\n",
    "plt.xlabel(\"Laplace smoothing value (log10)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B07GDiDdhWAq"
   },
   "source": [
    "### Part 9:\n",
    "\n",
    "Produce a model using Guassian Naive Bayes, which is intended for real-valued features, and evaluate performance. You will notice that it does not work so well. Diagnose the problem and apply a simple fix so that the model accuracy is around the same as for a Bernoulli Naive Bayes model. Show the model accuracy before your fix and the model accuracy after your fix.  Explain your solution.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* Consider the effects of theta and sigma.  These are stored in the model's `theta_` and `sigma_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBLbTMWChWAq"
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "# Fit and predict the Gaussian Naive Bayes model before the fix using real-valued features\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(mini_train_data, mini_train_labels)\n",
    "gnb_predicts = gnb.predict(dev_data)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Gaussian NB pre-fix accuracy score -\", classification_report(dev_labels, gnb_predicts, output_dict=True)['accuracy'])\n",
    "\n",
    "# Review the theta, sigma, and epsilon values\n",
    "print(\"\\nMean parameters of the Gaussian distribution without smoothing:\")\n",
    "print(f\"   Theta - {np.mean(gnb.theta_):.3f}\")\n",
    "print(f\"   Sigma - {np.mean(gnb.sigma_):.3f}\")\n",
    "print(f\"   Epsilon - {gnb.epsilon_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the Gaussian Naive Bayes model by increasing the var_smoothing effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run a hyperparameter search function to test a range of parameters\n",
    "def hyperparam_search(clf, hyperparams, train_data, train_labels, test_data, test_labels):\n",
    "    \n",
    "    '''\n",
    "    Runs a hyperparameter search on a classifer given an input list of sets of hyperparameters.\n",
    "    Each set of hyperparameters if passed into the classifier and the accuracy score of the \n",
    "    classifier is calculated. A list of accuracies containing each accuracy that is calculated\n",
    "    is return as output.\n",
    "    '''  \n",
    "    \n",
    "    # Initiliaze the list to store the accuracies\n",
    "    accuracies = []\n",
    "    \n",
    "    # For each set of hyperparameters, fit the classifier and store the prediction accuracy \n",
    "    for params in hyperparams:\n",
    "        model = clf()\n",
    "        model.set_params(**params)\n",
    "        model.fit(train_data, train_labels)\n",
    "        predicts = model.predict(test_data)\n",
    "        accuracies.append(classification_report(test_labels, predicts, output_dict=True)['accuracy'])\n",
    "        \n",
    "    return accuracies \n",
    "\n",
    "# Set the var_smoothing values to be tested and create a list of hyperparameters\n",
    "var_vals = np.linspace(1e-09,1,101)\n",
    "var_params = [{'var_smoothing':var} for var in var_vals]\n",
    "\n",
    "# Retrieve the list accuracies scores from the hyperparameter search\n",
    "smoothing_accs = hyperparam_search(GaussianNB, var_params, mini_train_data, mini_train_labels, dev_data, dev_labels)\n",
    "\n",
    "# Plot the accuracies against the var_smoothing parameters\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(var_vals, np.multiply(smoothing_accs,100), marker='o')\n",
    "plt.title(\"Gaussian NB Accuracies vs Variance Smoothing\")\n",
    "plt.xlabel(\"Variance smoothing\")\n",
    "plt.ylabel(\"Accuracy score %\")\n",
    "plt.show()\n",
    "\n",
    "# Show model accuracy, mean, sigma, and epsilon\n",
    "max_acc = max(smoothing_accs)\n",
    "max_var = var_vals[smoothing_accs.index(max_acc)]\n",
    "gnb1 = GaussianNB(var_smoothing=max_var).fit(mini_train_data, mini_train_labels)\n",
    "\n",
    "print(f\"Gaussian NB after-fix accuracy score ({max_var:.3f} variance smoothing) - {max_acc}\")\n",
    "print(\"\\nMean parameters of the Gaussian distribution with smoothing:\")\n",
    "print(f\"   Theta - {np.mean(gnb1.theta_):.3f}\")\n",
    "print(f\"   Sigma - {np.mean(gnb1.sigma_):.3f}\")\n",
    "print(f\"   Epsilon - {gnb1.epsilon_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the normalized greyscale values of the mini_train_data\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(mini_train_data.ravel(), bins=20)\n",
    "plt.title(\"Mini Train Data is Not Normally Distributed\")\n",
    "plt.xlabel(\"Normalized pixel greyscale value\")\n",
    "plt.xticks(np.arange(0,1.1,0.1))\n",
    "plt.show()\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SyHTEJohWAt"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "The Gaussian Naive Bayes algorithm assumes each feature has a underlying Gaussian, or normal, distribution. Within our digit data set, it is clear that the data are not drawn from a Gaussian distribution (as can be seen in the histogram above). From the histogram, we see that across all features, most of the values are skewed towards 0, with another smaller mode near 1. Not only is this the general trend, but many features will have much smaller variances compared to others, such as the pixels on the borders compared to those in the middle that in one digit the value could have a value close to 1, while for another digit the same pixel value could be close to 0. \n",
    "\n",
    "The Gaussian distribution will weight values that are farther away from the mean much smaller. Given that we can see that the original average mean for the features is ~0.13, values far away from this will not be as effective in the calculations of the frequency probabilities. In order to account for this, we can use the variance smoothing parameter to smooth the distribution and increase the weight of the values that are further away from the distribution mean. The variance smoothing parameter will effect the value of epsilon which is added to the sigma value. As a result, this will provide a more accurate prediction score given the improved weighting of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgZMuc1VhWAt"
   },
   "source": [
    "### Part 10:\n",
    "\n",
    "Because Naive Bayes produces a generative model, you can use it to generate digit images.\n",
    "\n",
    "Produce a Bernoulli Naive Bayes model and then use it to generate a 10x20 grid with 20 example images of each digit. Each pixel output should be either 0 or 1, based on comparing some randomly generated number to the estimated probability of the pixel being either 0 or 1.  Show the grid.\n",
    "\n",
    "Notes:\n",
    "* You can use np.random.rand() to generate random numbers from a uniform distribution.\n",
    "* The estimated probability of each pixel being 0 or 1 is stored in the model's `feature_log_prob_` attribute. You can use `np.exp()` to convert a log probability back to a probability.\n",
    "\n",
    "How do the generated digit images compare to the training digit images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktii-Mp-hWAu",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def generate_data(NB, num_examples=20):\n",
    "    \n",
    "    '''\n",
    "    Generates a input number of examples of each class based off the \n",
    "    posterior probabilities of an input Naive Bayes classifier. The default\n",
    "    number of examples is set to 20.\n",
    "    '''\n",
    "\n",
    "    # Initialize the lists to store the generated data and corresponding labels\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Convert the log probabilities for each class-pixel\n",
    "    P_digits = np.exp(NB.feature_log_prob_)\n",
    "    \n",
    "    # For every class, generate n=num_examples of data\n",
    "    for label, P_digit in zip(NB.classes_, P_digits):\n",
    "        for i in range(num_examples):\n",
    "            \n",
    "            # Generate random numbers between 0 to 1 for each pixel\n",
    "            random = np.random.rand(P_digit.shape[0])\n",
    "            \n",
    "            # Compare the randomly generated array with the estimated probabilites and store the data\n",
    "            data.append(P_digit > random)\n",
    "            labels.append(label)\n",
    "            \n",
    "    # Return the generated data and labels as numpy arrays\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "# Fit and predict the Bernoulli model\n",
    "bernoulli = BernoulliNB(binarize=None)\n",
    "bernoulli.fit(bin_mini_train_data, mini_train_labels)\n",
    "\n",
    "# Generate data and labels\n",
    "generated_data, generated_labels = generate_data(bernoulli, num_examples=20)\n",
    "\n",
    "# Produce the grid of generated digits\n",
    "create_grid(generated_data, generated_labels, num_examples=20)\n",
    "\n",
    "### STUDENT END ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuQd1fTGhWAw"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "As can be seen from the grid above, the generated examples tend to retain the general shape and structure of each digit, but have some added random noise compared to the training examples. This is due to the fact that the randomly generated numbers that are generated to determine whether a pixel is 0 or 1 adds some noise to the pixels. \n",
    "\n",
    "In addition, while the training examples had a range of greyscale values, in this case we have mapped each pixel to either 0 or 1 so there are only black or white pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksHMg73uhWAx"
   },
   "source": [
    "### Part 11:\n",
    "\n",
    "Recall that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior probability of the predicted class is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior probability and accuracy.  \n",
    "\n",
    "Produce a Bernoulli Naive Bayes model.  Evaluate performance: partition the dev set into several buckets based on the posterior probabilities of the predicted classes - think of a bin in a histogram- and then estimate the accuracy for each bucket. So, for each prediction, find the bucket to which the maximum posterior probability belongs, and update \"correct\" and \"total\" counters accordingly.  Show the accuracy for each bucket.\n",
    "\n",
    "Notes:\n",
    "* Set LaPlace smoothing (alpha) to the optimal value (from part 8).\n",
    "* Set binarization threshold to 0.\n",
    "* Train on the mini train set.\n",
    "* Evaluate perfromance on the dev set.\n",
    "\n",
    "How would you characterize the calibration for this Bernoulli Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1N-St12hWAy",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def calibration(posteriors, test_labels, buckets):\n",
    "    \n",
    "    '''\n",
    "    Calculates the calibration of a Naive Bayes model based on the correlation \n",
    "    of the posterior probabilities to the prediction accuracies. Assigns posterior \n",
    "    probabilites to bins based on the input bucket segments and calculates the \n",
    "    overall prediction accuracies of the labels within each bin. Returns the accuracy\n",
    "    for each bucket.\n",
    "    '''\n",
    "    \n",
    "    # Initial counters for correct labels, total labels, and accuracies per bucket\n",
    "    correct = [0 for i in buckets]\n",
    "    total = [0 for i in buckets]\n",
    "    accuracies = [0 for i in buckets]\n",
    "    \n",
    "    # Find the probability and index of the maximum posterior probability per example\n",
    "    max_probs = np.max(posteriors, axis=1)\n",
    "    max_indices = np.argmax(posteriors, axis=1)\n",
    "    \n",
    "    # For each example maximum probability, assign it to a bucket and compare the prediction to the label\n",
    "    for prob, index, label in zip(max_probs, max_indices, test_labels):\n",
    "        for i in range(len(buckets)):\n",
    "        \n",
    "            # If the probability is less or equal to the bucket, increment the total count for that bucket\n",
    "            if prob <= buckets[i]:\n",
    "                total[i] += 1\n",
    "                \n",
    "                # If the prediction is correct, increment the correct count for that bucket\n",
    "                if index == int(label):\n",
    "                    correct[i] += 1\n",
    "                    \n",
    "                break\n",
    "    \n",
    "    # For each bucket, calculate the accuracy and print the results\n",
    "    for i in range(len(buckets)):        \n",
    "        if total[i] > 0:\n",
    "            accuracies[i] = correct[i] / total[i]\n",
    "        print('Bin %d -> P(pred) between %.13f to %.13f:\\ttotal = %3d,\\taccuracy = %.3f' % \n",
    "          (i+1, 0 if i==0 else buckets[i-1], buckets[i], total[i], accuracies[i]))\n",
    "         \n",
    "    return accuracies\n",
    "        \n",
    "# Set up the Bernoulli NB model and retrieve the posterior probabilities\n",
    "bernoulli = BernoulliNB(alpha=0.001, binarize=0)\n",
    "bernoulli.fit(mini_train_data, mini_train_labels)\n",
    "posteriors = bernoulli.predict_proba(dev_data)\n",
    "\n",
    "# Create the bucket ranges\n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "\n",
    "# Calculate the model calibration\n",
    "accuracies = calibration(posteriors, dev_labels, buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign text labels to the bucket ranges\n",
    "bins = []\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "    if i==0:\n",
    "        bins.append(f'0-{buckets[i]}')\n",
    "    else:\n",
    "        bins.append(f'{buckets[i-1]}-{buckets[i]}')\n",
    "\n",
    "# Plot the relationship between posterior probability and accuracy\n",
    "plt.scatter([i for i in range(2,10)], accuracies[1:])\n",
    "plt.xlim(1.5,9.5)\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Weak Calibration Relationship Between Posterior Probability Bins and Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "### STUDENT END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-4qQsrrhWA1"
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "Given that the accuracy increases as the posterior probability increases, we can characterize the calibration of this Bernoulli Naive Bayes model as weakly calibrated. We can see this weak calibration relationship of posterior probability and accuracy from the plot above as well. Although not a perfect depiction of the relationship given that the bins towards the higher end represent much smaller ranges of posterior probabilities, we can still see that in general, as the probability increases so does the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLDISyh4hWA1"
   },
   "source": [
    "### Part 12 EXTRA CREDIT:\n",
    "\n",
    "Design new features to see if you can produce a Bernoulli Naive Bayes model with better performance.  Show the accuracy of a model based on the original features and the accuracy of the model based on the new features.\n",
    "\n",
    "Here are a few ideas to get you started:\n",
    "- Try summing or averaging the pixel values in each row.\n",
    "- Try summing or averaging the pixel values in each column.\n",
    "- Try summing or averaging the pixel values in each square block. (pick various block sizes)\n",
    "- Try counting the number of enclosed regions. (8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0)\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set (enhanced to comprise the new features).\n",
    "* Evaulate performance on the dev set.\n",
    "* Ensure that your code is well commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deskewing\n",
    "The new features that are used to produce an improved Bernoulli NB model are the deskewing of the train and test digits. By deskewing the trian and test data sets, we can create greater normalization among the digits of the same class and therefore lead to more accurate predictions. When the digits are deskewed, the pixel features will become more normalized across same class digits. In order to deskew images, affine transformations are applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P7h-t2ThWA2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT START ###\n",
    "\n",
    "def moments(digit):\n",
    "    \n",
    "    '''\n",
    "    A function that use moment equations to find the moments of a digit. \n",
    "    The function will calculate the moments of the center of mass (centroid) \n",
    "    and the covariance matrix of pixel intensities.\n",
    "    '''\n",
    "    \n",
    "    # Create a mesh grid\n",
    "    c0, c1 = np.mgrid[:digit.shape[0],:digit.shape[1]]\n",
    "    \n",
    "    # Uses moment equations to calculate weighted centroid and covariance matrix moment\n",
    "    pixel_sum = np.sum(digit) \n",
    "    mu_x = np.sum(c0*digit)/pixel_sum \n",
    "    mu_y = np.sum(c1*digit)/pixel_sum \n",
    "    var_x = np.sum((c0-mu_x)**2*digit)/pixel_sum\n",
    "    var_y = np.sum((c1-mu_y)**2*digit)/pixel_sum\n",
    "    cov_xy = np.sum((c0-mu_x)*(c1-mu_y)*digit)/pixel_sum \n",
    "    \n",
    "    # Weighted centroid \n",
    "    mu_vector = np.array([mu_x,mu_y]) \n",
    "\n",
    "    # Covariance matrix of pixel intensities\n",
    "    covariance_matrix = np.array([[var_x,cov_xy],[cov_xy,var_y]]) \n",
    "    \n",
    "    return mu_vector, covariance_matrix\n",
    "\n",
    "def deskew(digit):\n",
    "    \n",
    "    '''\n",
    "    Deskews a digit by calculating the offset and affine using the moments of the digit\n",
    "    in order to attempt to recenter the digit. The offset is the vector translation of the \n",
    "    digit and the affine is the vector skew angle that should be applied to the digit.\n",
    "    '''\n",
    "    \n",
    "    # Calculate the center of mass and covariance matrix \n",
    "    com, cov = moments(digit)\n",
    "    \n",
    "    # Calculate affine\n",
    "    alpha = cov[0,1]/cov[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    \n",
    "    # Calculate offset\n",
    "    ocenter = np.array(digit.shape)/2.0\n",
    "    offset = com-np.dot(affine,ocenter)\n",
    "    \n",
    "    # Initiliaze the deskewed digit matrix\n",
    "    output = np.zeros(digit.shape)\n",
    "    \n",
    "    # For every non-zero pixel, use affine transformation to calculate the new coordinates of the pixel\n",
    "    for row in range(digit.shape[0]):\n",
    "        for col in range(digit.shape[1]):\n",
    "            if digit[row][col] > 0:\n",
    "                new_coords = np.dot(np.linalg.inv(affine), ([[row], [col]]) - offset.reshape(-1,1)).astype(int)\n",
    "                output[new_coords[0][0]][new_coords[1][0]] = digit[row][col]\n",
    "                \n",
    "    return output\n",
    "\n",
    "# Deskew both dev and mini_train data                \n",
    "deskewed_dev_data = []\n",
    "deskewed_mini_train_data = []\n",
    "\n",
    "for data in dev_data:\n",
    "    deskewed_dev_data.append(deskew(data.reshape(28,28)).ravel())\n",
    "    \n",
    "for data in mini_train_data:\n",
    "    deskewed_mini_train_data.append(deskew(data.reshape(28,28)).ravel())\n",
    "\n",
    "\n",
    "# Fit and predict the Bernoulli model\n",
    "bern = BernoulliNB(binarize=0)\n",
    "bern.fit(mini_train_data, mini_train_labels)\n",
    "bern_predicts = bern.predict(dev_data)\n",
    "\n",
    "# Fit and predict the Bernoulli model with deskewed data\n",
    "bern_ds = BernoulliNB(binarize=0)\n",
    "bern_ds.fit(deskewed_mini_train_data, mini_train_labels)\n",
    "bern_ds_predicts = bern_ds.predict(deskewed_dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a binarization threshold of 0, with train and test data digits deskewed, the modeling accuracy increases from 80.9% up to 87.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy scores for each model\n",
    "print(\"Bernoulli NB accuracy score -\", classification_report(dev_labels, bern_predicts, output_dict=True)['accuracy'])\n",
    "print(\"Deskwed Bernoulli NB accuracy score -\", classification_report(dev_labels, bern_ds_predicts, output_dict=True)['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deskewed digits can be visualized to show how the digits tend to become normalized across each class (center aligned and rotated along the center). The axes below are included to show the alignment of the digits with\" the center. \n",
    "\n",
    "The first grid contains the original digits, while the second grid contains the deskewed digits (both grids contain the same examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_grid(dev_data, dev_labels, axes='on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_grid(deskewed_dev_data, dev_labels, num_examples=10, axes='on')\n",
    "\n",
    "### STUDENT END ###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "firstname_lastname_p1.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/MIDS-W207/Master/blob/master/Projects/firstname_lastname_p1.ipynb",
     "timestamp": 1557957807607
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
